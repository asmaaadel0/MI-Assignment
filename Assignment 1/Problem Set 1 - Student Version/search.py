from problem import HeuristicFunction, Problem, S, A, Solution
from collections import deque
from helpers.utils import NotImplemented

#TODO: Import any modules you want to use
import heapq

# All search functions take a problem and a state
# If it is an informed search function, it will also receive a heuristic function
# S and A are used for generic typing where S represents the state type and A represents the action type

# All the search functions should return one of two possible type:
# 1. A list of actions which represent the path from the initial state to the final state
# 2. None if there is no solution

def BreadthFirstSearch(problem: Problem[S, A], initial_state: S) -> Solution:
    #TODO: ADD YOUR CODE HERE

    """
    Perform Breadth-First Search to find a path from the initial state to a goal state.

    Args:
        problem (Problem[S, A]): The problem to be solved, containing state transitions and goal tests.
        initial_state (S): The initial state from which to start the search.

    Returns:
        Solution: A list of actions that define a path from the initial state to a goal state. 
                  Returns None if no solution is found.

    This function implements Breadth-First Search (BFS), an uninformed search algorithm. BFS explores states level by 
    level, starting from the initial state, until it reaches a goal state. The search is guided by a deque (frontier) 
    to keep track of states to explore. It ensures that shallower states are explored before deeper states.

    The function initializes a deque as the frontier to implement BFS and keeps track of the states in the frontier for 
    efficient state checking. It starts by adding the initial state and an empty path to the frontier.

    The search proceeds with a main loop that continues until the frontier is empty. In each iteration, the current 
    state is dequeued from the frontier, and its actions are expanded. For each action, a next state is generated by 
    applying the action to the current state.

    The function ensures that the next state is not None, not explored, and not in the frontier. If these conditions are 
    met, it checks if the next state is a goal state. If a goal state is reached, the function returns the path that 
    defines the solution.

    Otherwise, the next state is added to the frontier, and the updated path is included. The process continues, and the 
    function explores states in a breadth-first manner.

    If no solution is found after exploring all possible states, the function returns None.

    """

    # Initialize a deque as the frontier to implement Breadth-First Search.
    # Also, keep track of the states in the frontier for efficient state checking.
    frontier = deque()

    # Why a set: A set provides a data structure that allows efficient membership 
    # testing (i.e., checking if an element is already in the set) with an 
    # average-case time complexity of O(1).
    frontier_states = set() # set is used to keep track of the states currently in the frontier.
    
    frontier.append((initial_state, [])) # Add the initial state and an empty path to the frontier.
    frontier_states.add(initial_state) # Add the initial state to the frontier states.

    # average-case time complexity of O(1).
    explored = set() # Create a set to keep track of explored states.

    # Main loop for Breadth-First Search.
    while frontier:
        current_state, current_path = frontier.popleft() # Pop the first state in the queue of frontier to explore it.
        frontier_states.remove(current_state)  # Remove the state from the frontier.

        explored.add(current_state) # Mark the current state as explored.
        
        actions = problem.get_actions(current_state) # Get possible actions from the problem.

        # For loop to all possible actions.
        for action in actions:
            # Generate the next state by applying an action.
            next_state = problem.get_successor(current_state, action)

            # Check if the next state is not None, not explored, and not in the frontier.
            if next_state is not None and next_state not in explored and next_state not in frontier_states:
                # Check if the next state is the goal state.
                if problem.is_goal(next_state):
                    return current_path + [action]  # Return the path if the goal state is reached.
 
                next_path = current_path + [action] # Define the next path.
                frontier.append((next_state, next_path)) # Append the next state and the updated path to the queue.
                frontier_states.add(next_state)  # Add the state to the frontier.

    return None  # If no solution is found.

def DepthFirstSearch(problem: Problem[S, A], initial_state: S) -> Solution:
    #TODO: ADD YOUR CODE HERE

    """
    Perform Depth-First Search to find a path from the initial state to a goal state.

    Args:
        problem (Problem[S, A]): The problem to be solved, containing state transitions and goal tests.
        initial_state (S): The initial state from which to start the search.

    Returns:
        Solution: A list of actions that define a path from the initial state to a goal state. 
                  Returns None if no solution is found.

    This function performs Depth-First Search, an uninformed search algorithm that explores as far as possible along 
    each branch before backtracking. The search is guided by a stack (frontier) to keep track of states to explore. 
    The function continues exploring states until a goal state is reached or there are no more states in the stack.

    It initializes a stack for DFS and a set to track explored states. The search begins with the initial state in the stack. 
    States are popped from the stack, and their actions are expanded by applying actions to reach the next state. 
    If the next state is not explored, it is pushed onto the stack for future exploration.

    The function continues this process until a goal state is found or all possible states have been explored. 
    If a goal state is reached, a list of actions is returned, defining the path from the initial state to the goal state. 
    If no solution is found, the function returns None.
    """

    frontier = deque() # Initialize a stack for DFS
    frontier.append((initial_state, []))  # Initial state and empty path

    # average-case time complexity of O(1).
    explored = set() # Create a set to keep track of explored states

    # Main loop for Depth First Search
    while frontier:
        current_state, current_path = frontier.pop() # Pop the last state in the stack of frontier to explore it.

        # Check if the current state is the goal state
        if problem.is_goal(current_state):
            return current_path  # Return the path if the goal state is reached

        explored.add(current_state) # Mark the current state as explored

        actions = problem.get_actions(current_state) # Get possible actions from the problem

        # For loop to all possible actions.
        for action in actions:
            # Generate the next state by applying an action.
            next_state = problem.get_successor(current_state, action)

            # Check if next state not explored
            if next_state not in explored:
                next_path = current_path + [action] # Extend the current path with the chosen action
                frontier.append((next_state, next_path)) # Append the next state and the updated path to the stack
                explored.add(next_state) # Mark the current state as explored

    return None  # If no solution is found

def UniformCostSearch(problem: Problem[S, A], initial_state: S) -> Solution:
    #TODO: ADD YOUR CODE HERE

    """
    Perform Uniform Cost Search to find the optimal path from the initial state to a goal state.

    Args:
        problem (Problem[S, A]): The problem to be solved, containing state transitions, goal tests, and costs.
        initial_state (S): The initial state from which to start the search.

    Returns:
        Solution: A list of actions that define the optimal path from the initial state to a goal state. 
                  Returns None if no solution is found.

    This function performs Uniform Cost Search, a best-first search algorithm that expands states based on their path cost.
    The algorithm maintains a priority queue (frontier) where states are ordered by their cost. The search continues 
    until a goal state is reached or there are no more states to explore.

    It initializes an empty priority queue for the frontier and a set to track explored states. A global counter is used 
    to ensure unique priorities in case of tie-breaking.

    During the search, it expands states by applying available actions, computes the cost to reach each next state, 
    and enqueues them in the priority queue if they have a lower cost than previously encountered. The function 
    continues exploring states until a goal state is found or all possible states have been explored.

    The function returns a list of actions constituting the optimal path to the goal state or None if no solution is found.
    """

    # Initialize an empty priority queue for frontier
    frontier = []  # List of (priority, count, state, path)
    explored = set()  # Set to keep track of explored states
    counter = 0  # Global counter for priorities

    # Add the initial state to the frontier with a cost of 0 and an empty path
    heapq.heappush(frontier, (0, counter, initial_state, []))

    # Main loop for Uniform Cost Search
    while frontier:
        # Pop the node with the lowest cost (priority)
        cost, _, current_state, current_path = heapq.heappop(frontier)

        # Check if the current state is the goal state
        if problem.is_goal(current_state):
            return current_path  # Return the path if the goal state is reached

        # Check if the current state is explored
        if current_state in explored:
            continue  # Skip if already explored

        explored.add(current_state) # Mark the current state as explored

        actions = problem.get_actions(current_state) # Get possible actions from the problem

        # For loop to all possible actions
        for action in actions:
            # Generate the next state by applying an action.
            next_state = problem.get_successor(current_state, action)

            # Check if the next state is not None and not in the explored set
            if next_state is not None and next_state not in explored:
                # Calculate the cost of reaching the next state
                next_cost = cost + problem.get_cost(current_state, action)
                # Extend the current path with the chosen action
                next_path = current_path + [action]
                # Increment the counter to ensure unique priorities
                counter += 1  
                # Sort by cost without considering the nodes themselves
                heapq.heappush(frontier, (next_cost, counter, next_state, next_path))

    return None  # If no solution is found

def AStarSearch(problem: Problem[S, A], initial_state: S, heuristic: HeuristicFunction) -> Solution:
    #TODO: ADD YOUR CODE HERE

    """
    Perform an A* search to find the optimal path from the initial state to a goal state.

    Args:
        problem (Problem[S, A]): The problem to be solved, containing state transitions, goal tests, and costs.
        initial_state (S): The initial state from which to start the search.
        heuristic (HeuristicFunction): A heuristic function that estimates the cost from a state to the goal.

    Returns:
        Solution: A list of actions that define the optimal path from the initial state to a goal state. 
                  Returns None if no solution is found.

    This function performs A* search, which is a best-first search algorithm that expands states with the lowest 
    f(n) value (the sum of the cost g(n) and the heuristic h(n)). In case of tie-breaking, states with the same 
    f(n) value are enqueued in FIFO order based on their insertion time using a counter. The search continues 
    until a goal state is reached or there are no more states to explore.

    It maintains a priority queue (frontier) based on f(n), a dictionary (g_costs) to store the cost g(n) for each state,
    and a global counter for prioritizing states with the same f(n).

    During the search, it expands states by applying available actions, computes the g(n) cost for each next state, 
    and enqueues them in the priority queue if they have a lower g(n) cost than previously encountered. 

    The function returns a list of actions constituting the optimal path to the goal state or None if no solution is found.
    """

    frontier = []  # List of (f(n), counter, state, path)
    g_costs = {initial_state: 0}
    counter = 0  # Global counter for priorities

    # Push the initial state into the frontier with a priority based on the heuristic value.
    heapq.heappush(frontier, (heuristic(problem, initial_state), counter, initial_state, []))
    
    # Main loop for AStarSearch
    while frontier:
        # Pop the node with the lowest cost (priority)
        _, _, current_state, current_path = heapq.heappop(frontier)
        
        # Check if the current state is the goal state
        if problem.is_goal(current_state):
            return current_path  # Return the path if the goal state is reached
        
        actions = problem.get_actions(current_state) # Get possible actions from the problem

        # For loop to all possible actions
        for action in actions:
            # Generate the next state by applying an action.
            next_state = problem.get_successor(current_state, action)
            
            # Check if the next state is not None.
            if next_state is not None:
                # Calculate the cost of reaching the next state from the current state.
                next_g_cost = g_costs[current_state] + problem.get_cost(current_state, action)
                
                # Check if the next state has not been encountered before or if it has a lower cost.
                if next_state not in g_costs or next_g_cost < g_costs[next_state]:
                    g_costs[next_state] = next_g_cost
                    # Calculate the estimated total cost from the initial state to the goal state.
                    next_f_cost = next_g_cost + heuristic(problem, next_state)
                    
                    # Extend the current path with the chosen action
                    next_path = current_path + [action]
                    counter += 1  # Increment the counter to ensure unique priorities
                    # Push the next state into the frontier with the new priority.
                    # Sort by f(n) and use counter as tie-breaker to maintain FIFO order
                    heapq.heappush(frontier, (next_f_cost, counter, next_state, next_path))
    
    return None  # If no solution is found

def BestFirstSearch(problem: Problem[S, A], initial_state: S, heuristic: HeuristicFunction) -> Solution:
    #TODO: ADD YOUR CODE HERE

    """
    Performs Best First Search using a priority queue based on heuristic values.

    Args:
        problem (Problem): The problem to be solved.
        initial_state (S): The initial state of the problem.
        heuristic (HeuristicFunction): A heuristic function that estimates the cost to reach the goal from a state.

    Returns:
        Solution: A list of actions defining the path from the initial state to the goal state, or None if no solution is found.

    This function Performs Best First Search using a priority queue based on heuristic values.
    The function takes a problem, an initial state, and a heuristic function as inputs.
    
    It explores the state space in a manner that prioritizes states with lower heuristic values,
    aiming to reach the goal state efficiently. The search process maintains a frontier to track
    the states to be explored and employs a priority queue to determine the order of exploration.
    
    The function returns a list of actions representing the path from the initial state to the goal
    state or None if no solution is found.    
    """

    # Initialize an empty priority queue for the frontier
    frontier = []  # List of (priority, counter, state, path)
    explored = set()  # Set to keep track of explored states
    counter = 0  # Global counter for priorities

    # Add the initial state to the frontier with a priority determined by the heuristic and a counter
    heapq.heappush(frontier, (heuristic(problem, initial_state), counter, initial_state, []))
    
    # Main loop for Best First Search
    while frontier:
        # Pop the node with the lowest priority (heuristic value)
        _, _, current_state, current_path = heapq.heappop(frontier)

        # Check if the current state is the goal state
        if problem.is_goal(current_state):
            return current_path  # Return the path if the goal state is reached

        # Check if current state is explored
        if current_state in explored:
            continue  # Skip if already explored

        explored.add(current_state) # Mark the current state as explored

        actions = problem.get_actions(current_state) # Get possible actions from the problem for the current state
       
        # Loop through all possible actions
        for action in actions:
            # Generate the next state by applying an action
            next_state = problem.get_successor(current_state, action)

            # Check if the next state is not None and has not been explored
            if next_state is not None and next_state not in explored:
                counter += 1  # Increment the counter to ensure unique priorities
                next_path = current_path + [action] # Extend the current path with the chosen action
                # Add the next state to the frontier with a priority determined by the heuristic and a counter
                heapq.heappush(frontier, (heuristic(problem, next_state), counter, next_state, next_path))

    return None  # If no solution is found
